{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf0902c-cc14-4ae0-9dc3-0fa7c2491a8d",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3052ae27-0a40-4d08-b145-f84eb89e1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pathlib\n",
    "import tttrlib\n",
    "\n",
    "import os\n",
    "\n",
    "from feda_tools import twodim_hist as tdh\n",
    "from feda_tools import utilities as utils\n",
    "from feda_tools import analysis as an\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "import numpy.ma as ma\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import halfnorm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15b425-cdea-4f49-9141-974fccc68131",
   "metadata": {},
   "source": [
    "## Load the target PTU file\n",
    "\n",
    "-  **repo_path** is the path to the feda_tools repository. It must be updated to reflect the location of the repo on the system running this notebook before continuing with the analysis. <br>\n",
    "-  **dir** is the directory in which the target PTU file is located. <br>\n",
    "- **file_ptu** is the target PTU file on which the analysis will be performed. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56416358-d044-42cf-acff-e49b575d19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PTU Files\n",
    "# file_path = pathlib.Path('//130.127.188.19/projects/FoxP_FKH-DNA/20220314_FoxP1_data_all_NK/20220310_V78C_monomer_NK/V78C_monomer_FoxP1_1hr/burstwise_All 0.2027#30')\n",
    "# bid_path = pathlib.Path('//130.127.188.19/projects/FoxP_FKH-DNA/20220314_FoxP1_data_all_NK/20220310_V78C_monomer_NK/V78C_monomer_FoxP1_1hr/burstwise_All 0.2027#30/BIDs_30ph')\n",
    "\n",
    "### for testing purposes ###\n",
    "# file_path = pathlib.Path('C:/Users/2administrator/Documents/source/repos/feda_tools/test data/2022/03_02_22_Troubleshooting_detection_efficiencies/Combined_old_thresholds/Split_After_Adjust_HF_54000s_pinhole6-000000.ptu')\n",
    "\n",
    "# #total time 816.9 seconds for this file\n",
    "# dir = 'C:/Users/2administrator/Documents/source/repos/feda_tools/test data/2022/03_02_22_Troubleshooting_detection_efficiencies/'\n",
    "# file_ptu = dir + 'Combined_old_thresholds/Split_After_Adjust_HF_54000s_pinhole6-000000.ptu'\n",
    "# file_irf = dir + 'H2O_300s_adjust_thresholds.ptu'\n",
    "# file_bkg = dir + 'PBS_300s_adjust_thresholds.ptu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d38e020-b770-49c7-8247-dbe675998f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Absolute path to the repository\n",
    "repo_path = '/Users/frankie/Documents/source/repos/feda_tools/'\n",
    "\n",
    "# Load PTU Files\n",
    "# file_path = pathlib.Path('//130.127.188.19/projects/FoxP_FKH-DNA/20220314_FoxP1_data_all_NK/20220310_V78C_monomer_NK/V78C_monomer_FoxP1_1hr/burstwise_All 0.2027#30')\n",
    "# bid_path = pathlib.Path('//130.127.188.19/projects/FoxP_FKH-DNA/20220314_FoxP1_data_all_NK/20220310_V78C_monomer_NK/V78C_monomer_FoxP1_1hr/burstwise_All 0.2027#30/BIDs_30ph')\n",
    "\n",
    "### for testing purposes ###\n",
    "# file_path = pathlib.Path('C:/Users/2administrator/Documents/source/repos/feda_tools/test data/2022/03_02_22_Troubleshooting_detection_efficiencies/Combined_old_thresholds/Split_After_Adjust_HF_54000s_pinhole6-000000.ptu')\n",
    "\n",
    "# get all PTU files in the target directory.\n",
    "dir = repo_path + '/test data/2022/03_02_22_Troubleshooting_detection_efficiencies/Combined_old_thresholds/'\n",
    "ptu_files = utils.get_ptu_files(dir)\n",
    "ptu_files.sort()\n",
    "file_ptu = ptu_files[0]\n",
    "# file_irf = dir + 'H2O_300s_adjust_thresholds.ptu'\n",
    "# file_bkg = dir + 'PBS_300s_adjust_thresholds.ptu'\n",
    "\n",
    "if pathlib.Path(file_ptu).exists():\n",
    "    print(\"The path exists.\")\n",
    "else:\n",
    "    print(\"The path does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c37af5-7223-4a4f-b10e-0eacfb495a03",
   "metadata": {},
   "source": [
    "## Initialize tttrlib data and extract important global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bf7205d-e2f0-42bd-92a1-916a43bf2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define analysis window for subset of PTU\n",
    "min_event = 0\n",
    "max_event = 300000\n",
    "\n",
    "data_ptu = tttrlib.TTTR(file_ptu, 'PTU')\n",
    "routing_channels =  data_ptu.routing_channels\n",
    "\n",
    "# total duration in seconds\n",
    "all_macro_times = data_ptu.macro_times\n",
    "micro_res = data_ptu.get_header().micro_time_resolution\n",
    "macro_res =data_ptu.get_header().macro_time_resolution\n",
    "total_duration = all_macro_times[-1] * macro_res\n",
    "\n",
    "# data_irf = tttrlib.TTTR(file_irf, 'PTU')\n",
    "# all_macro_times_irf = data_irf.macro_times\n",
    "# all_micro_times_irf = data_irf.micro_times\n",
    "# routing_channels_irf =  data_irf.routing_channels\n",
    "\n",
    "# data_bkg = tttrlib.TTTR(file_bkg, 'PTU')\n",
    "# all_macro_times_bkg = data_bkg.macro_times\n",
    "# all_micro_times_bkg = data_bkg.micro_times\n",
    "# routing_channels_bkg =  data_bkg.routing_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fe224-8caf-46a3-9a0d-532345adaab1",
   "metadata": {},
   "source": [
    "## Determine analysis settings for bur, bg4, by4, and br4 calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "681c0cfe-13f2-4e14-9e37-a3183b60673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# photon count threshold for burst selection\n",
    "min_photon_count = 60\n",
    "\n",
    "# this window changes for br4 and by4\n",
    "# bg4 parameters\n",
    "bg4_micro_time_min = 0\n",
    "bg4_micro_time_max = 12499\n",
    "\n",
    "# flourescence anisotropy parameters\n",
    "g_factor = 0.4\n",
    "l1_japan_corr = 0.0308\n",
    "l2_japan_corr = 0.0368\n",
    "\n",
    "# # bkg signals required for r Scatter calculations\n",
    "bg4_bkg_para = 0\n",
    "bg4_bkg_perp = 0\n",
    "\n",
    "\n",
    "# MLE parameters\n",
    "num_bins = 128\n",
    "bin_width = macro_res/micro_res/num_bins/1000 # in nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4b2f2-15a8-4f05-9bd5-000d6edeaf5b",
   "metadata": {},
   "source": [
    "## Burst Selection: Calculate Interphoton Arrival Time \n",
    "\n",
    "- Each detected photon has a time of detection encoded by the macro time + the micro time. **all_macro_times** and **all_micro_times** are arrays whose index is represents the detected photons in order of detection, while the value represents the associated macro or micro time for each photon.\n",
    "- **macro_res** and **micro_res** represent the resolution of the macro and micro times in seconds.\n",
    "- The **macro time** indicates the time in units of **macro_res** that the excitation laser was last fired directly before this photon was detected.\n",
    "- The **micro time** indicates the amount of time in units of **micro_res** that has elapsed since the excitation laser was last fired at which the photon was detected, i.e. it's the amount of time elapsed from the macro time at which the photon was detected.\n",
    "- The interphoton arrival time is calculated by iterating through **all_macro_times** and **all_micro_times** and calculating the time elapsed between each photon detection event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "830cd919-50e6-4812-80cc-618ebbd8b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "photon_time_intervals = an.calc_interphoton_arrival_times(data_ptu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20dfecc0-5424-4b37-ae8e-2570935704a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3073616332567326\n"
     ]
    }
   ],
   "source": [
    "print(photon_time_intervals[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0016ec6-6c36-498d-a6b4-a2e2f1410c95",
   "metadata": {},
   "source": [
    "## Burst Selection: Calculate the Log of the Running Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a02b49a-8a02-49a7-b0f7-84055deb7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the window size for the running average\n",
    "window_size = 30\n",
    "\n",
    "# Calculate the running average\n",
    "running_avg = an.calc_running_average(photon_time_intervals, window_size)\n",
    "\n",
    "# Create x axis array to match the data.\n",
    "xarr = np.arange(window_size - 1, len(photon_time_intervals))\n",
    "\n",
    "# Calculate the base 10 log of the running average\n",
    "logrunavg = np.log10(running_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a3ff9-882b-4153-b8b1-90f035c2113f",
   "metadata": {},
   "source": [
    "## Burst Selection: Visualize the Photon Events with an Interactive Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6836af45-ca6c-4d31-b625-06212e102805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the running average as a 2D histogram with 1D histograms on the margins\n",
    "%matplotlib qt\n",
    "bins = {\"x\":141, \"y\": 141}\n",
    "xrange = {\"min\" : min_event, \"max\" : max_event}\n",
    "yrange = {\"min\" : -6, \"max\" : 2}\n",
    "fig, ax, twodimdata = tdh.make_plot(xarr, logrunavg, \"x\", \"y\",xrange ,yrange, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcc7ee-060e-4ef7-b9bd-b3fdfd77e4d6",
   "metadata": {},
   "source": [
    "## Burst Selection: Estimate the Mean of the Gaussian Background Noise \n",
    "\n",
    "\n",
    "Check that the mean is estimated well by the max counts. The data on the right-half (blue/purple) estimates the right half of the Gaussian noise. The left-most bin of the right-half data is the estimated mean. When the estimated mean is well aligned with the peak, then you may continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ee0bf9-aeec-493d-80a5-7cae1bd24a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the log of the running avg interphoton arrival times to find the overall data profile.\n",
    "counts_logrunavg, bins_logrunavg = np.histogram(logrunavg, bins = bins['y'])\n",
    "\n",
    "# Find the index of the maximum counts value.\n",
    "index_of_max = np.argmax(counts_logrunavg)\n",
    "\n",
    "# Use the index of the max counts to find the corresponding interphoton time bin.\n",
    "mean_est = bins_logrunavg[index_of_max]\n",
    "\n",
    "# Compress the filtered data to remove the masked values for plotting\n",
    "filtered_logrunavg = ma.masked_less(logrunavg, mean_est).compressed()\n",
    "\n",
    "# Plot to inspect the result\n",
    "counts_logrunavg, bins_logrunavg, _ = plt.hist(logrunavg, bins = bins['y'], alpha=0.6, color='r')\n",
    "plt.hist(filtered_logrunavg, bins = bins_logrunavg, alpha=0.6, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173206f-be3a-4cc9-8035-9964df3d1f8d",
   "metadata": {},
   "source": [
    "## Burst Selection: Fit a Half-Norm to the Right Tail of the Data and Extract the Std. Dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afeac049-a791-4845-b63b-394cdbdd0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with halfnorm. visualize for best fit testing. get mu and std dev. consider finding max and setting location as mean\n",
    "mu, std = halfnorm.fit(filtered_logrunavg)\n",
    "\n",
    "# counts_logrunavg, bins_logrunavg, _ = plt.hist(logrunavg, bins = bins['y'], density= True, alpha=0.6, color='r')\n",
    "plt.hist(filtered_logrunavg, bins = bins['y'], density = True, alpha=0.6, color='r')\n",
    "\n",
    "# Plot the PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = halfnorm.pdf(x, mu, std)\n",
    "\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit Values: {:.2f} and {:.2f}\".format(mu, std)\n",
    "plt.title(title)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbfa67-9287-4eef-933f-cf936e8dde57",
   "metadata": {},
   "source": [
    "## Burst Selection: Filter Out the Noise and Plot to Inspect\n",
    "Set the threshold to 4sigma to the left of the mean, effectively isolating the protien dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30c2ab99-bc54-4a48-9415-d958b6a41db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using std from halfnorm fit, set the threshold for filtering out noise. Then, filter out noise. Raise 10 to threshold later for burst selection\n",
    "threshold_value = mu - 4*std #raise 10 to the power of this threshold to obtain the threshold in Paris.\n",
    "filtered_values = ma.masked_greater(logrunavg, threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb557882-5c02-4f69-a58f-1a4a98742716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frankie/anaconda3/envs/testing/lib/python3.11/site-packages/ipykernel/eventloops.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "# visualize the log running average and the threshold values\n",
    "plt.plot(xarr, logrunavg, label='Running Average', linestyle='None', marker = 'o', markersize = 5)\n",
    "plt.plot(xarr, filtered_values, label='Threshold Values', linestyle='None', marker = '.', markersize = 5)\n",
    "plt.xlabel('Photon Event #')\n",
    "plt.ylabel('log(Photon Interval Time)')\n",
    "plt.legend()\n",
    "plt.xlim(min_event, max_event)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09a742-61c9-41be-b280-e90ab34602ec",
   "metadata": {},
   "source": [
    "## Burst Selection: Create the Burst Index By Filtering with the Threshold.\n",
    "- The **burst_index** will contain a burst at each index. A burst is a collection of photon events that we hope contains protien dynamics information!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87a38c84-e5dc-47aa-9723-0a019de722f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a burst index. Each list is a burst, and each list contains the indices of \n",
    "### the photon events in the original data.\n",
    "burst_index = an.extract_unmasked_indices(filtered_values)\n",
    "\n",
    "# Store result in the burst dict.\n",
    "burst_dict = {file_ptu : burst_index}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c92b0-8575-4dc7-a0e7-2223ac4462b9",
   "metadata": {},
   "source": [
    "## Burst Selection: Generate the Burst Indices for the Remaining PTU Files in the Directory\n",
    "Using the parameters for the first PTU file, batch process the remaining PTU files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f2a3093-9209-4c4a-aefc-7e0539bfae3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_After_Adjust_HF_54000s_pinhole6-000001.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000002.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000003.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000004.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000005.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000006.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000007.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000008.ptu\n",
      "Split_After_Adjust_HF_54000s_pinhole6-000009.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000000.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000001.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000002.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000003.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000004.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000005.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000006.ptu\n",
      "Split_After_Adjust_LF_7200s_pinhole6-000007.ptu\n"
     ]
    }
   ],
   "source": [
    "for file in ptu_files[1:]:\n",
    "    print(file)\n",
    "    filtered_values = ma.masked_greater(logrunavg, threshold_value)\n",
    "    burst_index = an.extract_unmasked_indices(filtered_values)\n",
    "    burst_dict[file] = burst_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebd64631-6348-4302-8a31-6b82efc42c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( dir + 'burst_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(burst_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
