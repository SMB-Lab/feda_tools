{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf0902c-cc14-4ae0-9dc3-0fa7c2491a8d",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3052ae27-0a40-4d08-b145-f84eb89e1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pathlib\n",
    "import tttrlib\n",
    "\n",
    "import os\n",
    "\n",
    "from feda_tools import twodim_hist as tdh\n",
    "from feda_tools import utilities as utils\n",
    "from feda_tools import analysis as an\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "import numpy.ma as ma\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import halfnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15b425-cdea-4f49-9141-974fccc68131",
   "metadata": {},
   "source": [
    "## Load target PTU file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56416358-d044-42cf-acff-e49b575d19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PTU Files\n",
    "# file_path = pathlib.Path('//130.127.188.19/projects/FoxP_FKH-DNA/20220314_FoxP1_data_all_NK/20220310_V78C_monomer_NK/V78C_monomer_FoxP1_1hr/burstwise_All 0.2027#30')\n",
    "# bid_path = pathlib.Path('//130.127.188.19/projects/FoxP_FKH-DNA/20220314_FoxP1_data_all_NK/20220310_V78C_monomer_NK/V78C_monomer_FoxP1_1hr/burstwise_All 0.2027#30/BIDs_30ph')\n",
    "\n",
    "### for testing purposes ###\n",
    "# file_path = pathlib.Path('C:/Users/2administrator/Documents/source/repos/feda_tools/test data/2022/03_02_22_Troubleshooting_detection_efficiencies/Combined_old_thresholds/Split_After_Adjust_HF_54000s_pinhole6-000000.ptu')\n",
    "\n",
    "#total time 816.9 seconds for this file\n",
    "file_p ='C:/Users/2administrator/Documents/source/repos/feda_tools/test data/2022/03_02_22_Troubleshooting_detection_efficiencies/Combined_old_thresholds/Split_After_Adjust_HF_54000s_pinhole6-000000.ptu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c37af5-7223-4a4f-b10e-0eacfb495a03",
   "metadata": {},
   "source": [
    "## Initialize tttrlib data and extract important global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bf7205d-e2f0-42bd-92a1-916a43bf2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tttrlib.TTTR(file_p, 'PTU')\n",
    "all_macro_times = data.macro_times\n",
    "all_micro_times = data.micro_times\n",
    "routing_channels =  data.routing_channels\n",
    "\n",
    "#in seconds. usually the first plots are in ms to see the bursts.\n",
    "macro_res =data.get_header().macro_time_resolution\n",
    "micro_res = data.get_header().micro_time_resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4b2f2-15a8-4f05-9bd5-000d6edeaf5b",
   "metadata": {},
   "source": [
    "## Calculate photon time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e6c51c-a284-49fc-a41f-04b03dc3f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through macro and micro times to calculate delta time between photon events\n",
    "arr_size = len(all_macro_times) - 1\n",
    "photon_time_intervals = np.zeros(arr_size, dtype = np.float64)\n",
    "lw = 0.25\n",
    "for i in range(0, len(photon_time_intervals)):\n",
    "    photon_1 = (all_macro_times[i]*macro_res) + (all_micro_times[i]*micro_res)\n",
    "    photon_2 = (all_macro_times[i+1]*macro_res) + (all_micro_times[i+1]*micro_res)\n",
    "    photon_time_intervals[i] = (photon_2 - photon_1)*1000\n",
    "\n",
    "# create photon ID array\n",
    "photon_ids = np.arange(1, arr_size + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fb470b-fc0e-49f6-98e5-6d16f39467f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3073616332567326\n"
     ]
    }
   ],
   "source": [
    "print(photon_time_intervals[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26a8f8-c3e7-4bae-8ffb-d13b35b816b9",
   "metadata": {},
   "source": [
    "## Plot the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d38e86b8-8598-443e-83b6-561d1fd0b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interactive\n",
    "%matplotlib qt\n",
    "\n",
    "# raw data, no running average\n",
    "plt.plot(photon_ids, np.log(photon_time_intervals), linewidth = 0.25)\n",
    "plt.xlim(0, 91000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10148b92-bbb6-4c80-a1ca-d333d33c4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the running average\n",
    "cumulative_sum = np.cumsum(photon_time_intervals)\n",
    "running_average = cumulative_sum / np.arange(1, len(photon_time_intervals) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc61a1d-c404-442c-9c74-4029fe39164a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x290a4005450>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(photon_ids, running_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0016ec6-6c36-498d-a6b4-a2e2f1410c95",
   "metadata": {},
   "source": [
    "## Plot the log of the running average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a02b49a-8a02-49a7-b0f7-84055deb7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_average(data, window_size):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "# Create a NumPy array\n",
    "data = photon_time_intervals\n",
    "\n",
    "# Set the window size for the running average\n",
    "window_size = 30\n",
    "\n",
    "# Calculate the running average\n",
    "running_avg = running_average(data, window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4625dea-483e-47b1-9d90-ea31924d5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the running average\n",
    "# plt.plot(data, label='Original Data')\n",
    "lw = 0.25\n",
    "xarr = np.arange(window_size - 1, len(data))\n",
    "logrunavg = np.log(running_avg)\n",
    "plt.plot(xarr, logrunavg, label='Running Average', linewidth = lw)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.xlim(0, 91000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a3ff9-882b-4153-b8b1-90f035c2113f",
   "metadata": {},
   "source": [
    "## Plot the log of the running average using 2D heat map to better visualize noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6836af45-ca6c-4d31-b625-06212e102805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the running average as a 2D histogram with 1D histograms on the margins\n",
    "\n",
    "bins = {\"x\":141, \"y\": 141}\n",
    "xrange = {\"min\" : 0, \"max\" : 91000}\n",
    "yrange = {\"min\" : -6, \"max\" : 2}\n",
    "fig, ax, twodimdata = tdh.make_plot(xarr, logrunavg, \"x\", \"y\",xrange ,yrange, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcc7ee-060e-4ef7-b9bd-b3fdfd77e4d6",
   "metadata": {},
   "source": [
    "## Visually estimate the norm center and visualize the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ee0bf9-aeec-493d-80a5-7cae1bd24a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### estimate the half gaussian fit on the top half of the data.\n",
    "# set the threshold based on visual inspection. here, threshold ~ mu\n",
    "threshold_value = -.34\n",
    "\n",
    "# compress the filtered data to remove the masked values\n",
    "filtered_logrunavg = ma.masked_less(logrunavg, threshold_value).compressed()\n",
    "\n",
    "# Set all masked values to zero\n",
    "counts_logrunavg, bins_logrunavg, _ = plt.hist(logrunavg, bins = bins['y'], alpha=0.6, color='r')\n",
    "plt.hist(filtered_logrunavg, bins = bins_logrunavg, alpha=0.6, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afeac049-a791-4845-b63b-394cdbdd0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with halfnorm. visualize for best fit testing. get mu and std dev\n",
    "mu, std = halfnorm.fit(filtered_logrunavg)\n",
    "\n",
    "# counts_logrunavg, bins_logrunavg, _ = plt.hist(logrunavg, bins = bins['y'], density= True, alpha=0.6, color='r')\n",
    "plt.hist(filtered_logrunavg, bins = bins['y'], density = True, alpha=0.6, color='r')\n",
    "\n",
    "# Plot the PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = halfnorm.pdf(x, mu, std)\n",
    "\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit Values: {:.2f} and {:.2f}\".format(mu, std)\n",
    "plt.title(title)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbfa67-9287-4eef-933f-cf936e8dde57",
   "metadata": {},
   "source": [
    "## Using the halfnorm fit, define 2sigma threshold and plot for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30c2ab99-bc54-4a48-9415-d958b6a41db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using std from halfnorm fit, set the threshold for filtering out noise. Then, filter out noise.\n",
    "threshold_value = mu - 2*std\n",
    "filtered_values = ma.masked_greater(logrunavg, threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb557882-5c02-4f69-a58f-1a4a98742716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the log running average and the threshold values\n",
    "plt.plot(xarr, logrunavg, label='Running Average', linestyle='None', marker = 'o', markersize = 5)\n",
    "plt.plot(xarr, filtered_values, label='Threshold Values', linestyle='None', marker = '.', markersize = 5)\n",
    "plt.xlabel('Photon Event #')\n",
    "plt.ylabel('log(Photon Interval Time)')\n",
    "plt.legend()\n",
    "plt.xlim(0, 91000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09a742-61c9-41be-b280-e90ab34602ec",
   "metadata": {},
   "source": [
    "## Extract the photon data that meets the thresdhold condition and create a burst index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921c30b5-1b0e-451e-a9d4-4268923e7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define function for extracting the unmasked segments from the thresholded data.\n",
    "def extract_unmasked_indices(masked_array):\n",
    "    unmasked_indices_lists = []\n",
    "    current_indices = []\n",
    "\n",
    "    # iterate through masked array and collect unmasked index segments\n",
    "    for i, value in enumerate(masked_array):\n",
    "        if np.ma.is_masked(value):\n",
    "            if current_indices:\n",
    "                unmasked_indices_lists.append(current_indices)\n",
    "                current_indices = []\n",
    "        else:\n",
    "            current_indices.append(i)\n",
    "\n",
    "    # handle the last segment\n",
    "    if current_indices:\n",
    "        unmasked_indices_lists.append(current_indices)\n",
    "\n",
    "    return unmasked_indices_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87a38c84-e5dc-47aa-9723-0a019de722f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a burst index. Each list is a burst, and each list contains the indices of \n",
    "### the photon events in the original data.\n",
    "burst_index = extract_unmasked_indices(filtered_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ada07-0bca-45b7-ac8a-8ec53569ba34",
   "metadata": {},
   "source": [
    "## Create bi4_bur dataframe and calculate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29764f25-1754-46cc-8083-f05ce5acb7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2administrator\\AppData\\Local\\Temp\\ipykernel_27264\\2822540145.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bi4_bur_df = pd.concat([bi4_bur_df, new_record], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "### create bi4_bur dataframe ###\n",
    "################################\n",
    "min_photon_count = 100\n",
    "\n",
    "# prepare empty dataframe to calculate values\n",
    "bi4_bur_df = pd.DataFrame(columns=\n",
    "                          ['First Photon', \n",
    "                           'Last Photon', \n",
    "                           'Duration (ms)', \n",
    "                           'Mean Macro Time (ms)', \n",
    "                           'Number of Photons', \n",
    "                           'Count Rate (kHz)'])\n",
    "\n",
    "### calculate each burst record and store in df\n",
    "for burst in burst_index:\n",
    "\n",
    "    # filter out bursts with one or less photons.\n",
    "    if len(burst) <= min_photon_count:\n",
    "        continue\n",
    "\n",
    "    #############################\n",
    "    ### First and Last Photon ###\n",
    "    #############################\n",
    "    \n",
    "    first_photon = burst[0]\n",
    "    last_photon = burst[-1]\n",
    "\n",
    "    ##########################\n",
    "    ### Duration (ms) calc ###\n",
    "    ##########################\n",
    "    \n",
    "    lp_time = all_macro_times[last_photon]*macro_res + all_micro_times[last_photon]*micro_res\n",
    "    fp_time = all_macro_times[first_photon]*macro_res + all_micro_times[first_photon]*micro_res\n",
    "    lp_time_ms = lp_time*1000\n",
    "    fp_time_ms = fp_time*1000\n",
    "    duration = (lp_time_ms - fp_time_ms)\n",
    "\n",
    "    #################################\n",
    "    ### Mean Macro Time (ms) Calc ###\n",
    "    #################################\n",
    "    \n",
    "    # get all the macro times corresponding to the photons in this burst\n",
    "    macro_times = all_macro_times[burst[0]]*macro_res*1000\n",
    "    \n",
    "    # calculate the mean\n",
    "    mean_macro_time = np.mean(macro_times)\n",
    "\n",
    "    ##############################\n",
    "    ### Number of Photons calc ###\n",
    "    ##############################\n",
    "    num_photons = len(burst)\n",
    "\n",
    "    #######################\n",
    "    ### Count Rate calc ###\n",
    "    #######################\n",
    "    count_rate = num_photons / duration\n",
    "\n",
    "    #################################\n",
    "    ### Duration (green)(ms) calc ###\n",
    "    #################################\n",
    "    \n",
    "    # Assuming you have your list of indexes\n",
    "    list_of_indexes = burst\n",
    "    \n",
    "    # Get the routing channel per index data\n",
    "    routing_channels = data.routing_channels\n",
    "    \n",
    "    # Create boolean masks for channels 0 and 2 to select the green channels\n",
    "    mask_channel_0 = routing_channels[list_of_indexes] == 0\n",
    "    mask_channel_2 = routing_channels[list_of_indexes] == 2\n",
    "    \n",
    "    # Use boolean masks to filter the indexes\n",
    "    indexes_channel_0 = np.array(list_of_indexes)[mask_channel_0]\n",
    "    indexes_channel_2 = np.array(list_of_indexes)[mask_channel_2]\n",
    "    \n",
    "    # Output the filtered indexes\n",
    "    # print(\"Indexes corresponding to channel 0:\", indexes_channel_0)\n",
    "    # print(\"Indexes corresponding to channel 2:\", indexes_channel_2)\n",
    "    \n",
    "    # Find the minimum and maximum indexes across both resulting arrays. These are first and last green \n",
    "    # photon in this burst. handle situations where only one channel has photons or none have photons.\n",
    "    if len(indexes_channel_0) > 0 and len(indexes_channel_2) > 0:\n",
    "        first_green_photon = min(np.min(indexes_channel_0), np.min(indexes_channel_2))\n",
    "        last_green_photon = max(np.max(indexes_channel_0), np.max(indexes_channel_2))\n",
    "    elif len(indexes_channel_0) >= 2:\n",
    "        first_green_photon = np.min(indexes_channel_0)\n",
    "        last_green_photon = np.max(indexes_channel_0)\n",
    "    elif len(indexes_channel_2) >= 2:\n",
    "        first_green_photon = np.min(indexes_channel_2)\n",
    "        last_green_photon = np.max(indexes_channel_2)\n",
    "    else:\n",
    "        first_green_photon = None\n",
    "        last_green_photon = None\n",
    "\n",
    "    # Calculate duration or set as NaN\n",
    "    if first_green_photon != None and last_green_photon != None:\n",
    "        lgp_time = all_macro_times[last_green_photon]*macro_res + all_micro_times[last_green_photon]*micro_res\n",
    "        fgp_time = all_macro_times[first_green_photon]*macro_res + all_micro_times[first_green_photon]*micro_res\n",
    "        lgp_time_ms = lgp_time*1000\n",
    "        fgp_time_ms = fgp_time*1000\n",
    "        duration_green = (lgp_time_ms - fgp_time_ms)\n",
    "    else:\n",
    "        duration_green = np.nan\n",
    "\n",
    "    #########################################\n",
    "    #### Mean Macro Time (green)(ms) calc ###\n",
    "    #########################################\n",
    "    \n",
    "    # get all the macro times corresponding to the photons in this burst\n",
    "    macro_times_ch0 = all_macro_times[indexes_channel_0]*macro_res*1000\n",
    "    macro_times_ch2 = all_macro_times[indexes_channel_2]*macro_res*1000\n",
    "    \n",
    "    # Concatenate the arrays along the appropriate axis\n",
    "    combined_macro_times = np.concatenate([macro_times_ch0, macro_times_ch2], axis=0)\n",
    "    \n",
    "    # calculate the mean\n",
    "    mean_macro_time_green = np.mean(combined_macro_times, axis=0)\n",
    "\n",
    "    #################################\n",
    "    ### Number of Photons (green) ###\n",
    "    #################################\n",
    "    num_photons_gr = len(indexes_channel_0) + len(indexes_channel_2)\n",
    "\n",
    "    ########################\n",
    "    ### Green Count Rate ###\n",
    "    ########################\n",
    "    count_rate_gr = num_photons_gr / duration_green\n",
    "    \n",
    "    new_row = {'First Photon': [first_photon],'Last Photon': [last_photon],\n",
    "               'Duration (ms)': [duration],'Mean Macro Time (ms)': [mean_macro_time],\n",
    "               'Number of Photons': [num_photons], 'Count Rate (kHz)': [count_rate],\n",
    "               'Duration (green) (ms)': [duration_green], \n",
    "               'Mean Macro Time (green) (ms)': [mean_macro_time_green],\n",
    "               'Number of Photons (green)': [num_photons_gr],\n",
    "               'Green Count Rate (kHz)': count_rate_gr\n",
    "              }\n",
    "    \n",
    "    new_record = pd.DataFrame.from_dict(new_row)\n",
    "    \n",
    "    ### append record to df\n",
    "    bi4_bur_df = pd.concat([bi4_bur_df, new_record], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbacacab-3791-4494-afe8-429e41ebf5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
